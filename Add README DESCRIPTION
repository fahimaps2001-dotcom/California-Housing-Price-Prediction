California Housing Price Prediction ğŸ 

â€‹Objective
â€‹This project evaluates various supervised learning regression techniques by applying them to the California Housing Dataset. The goal is to predict the median house value (MedHouseVal) based on features like median income, house age, and location (latitude/longitude).
â€‹ğŸ›  Tech Stack
â€‹Language: Python 3.x
â€‹Libraries: * Scikit-Learn: Model implementation, scaling, and evaluation.
â€‹Pandas & NumPy: Data manipulation.
â€‹Matplotlib & Seaborn: Data visualization and EDA.

â€‹ğŸ“‹ Project Workflow
â€‹1. Data Preprocessing & EDA
â€‹Standardization: Applied StandardScaler to ensure all features contribute equally, which is vital for distance-based models like SVR.
â€‹EDA: Generated a correlation heatmap to identify strong predictors (e.g., MedInc).

â€‹2. Model Implementation
â€‹We implemented and compared five major regression algorithms:
â€‹Linear Regression: Baseline model.
â€‹Decision Tree Regressor: Captures non-linear relationships.
â€‹Random Forest Regressor: An ensemble of trees to reduce variance.
â€‹Gradient Boosting Regressor: Sequential tree building to minimize error.
â€‹Support Vector Regressor (SVR): High-dimensional hyperplane optimization.

â€‹3. Evaluation Metrics
â€‹Models were evaluated using:
â€‹R-Squared (R^2): Measures the proportion of variance explained.
â€‹Mean Squared Error (MSE): Penalizes large errors.
â€‹Mean Absolute Error (MAE): Provides an average error magnitude.

â€‹4. Optimization
â€‹Cross-Validation: Used 5-fold CV to ensure model stability across different data splits.
â€‹Hyperparameter Tuning: Conducted GridSearchCV on the top-performing model to find optimal parameters (learning rate, depth, etc.).

Results Summary
â€‹Best Model: Gradient Boosting Regressor (Highest R^2, Lowest MSE).
â€‹Reasoning: The dataset contains complex spatial relationships (Longitude/Latitude) and non-linear interactions that ensemble boosting methods are uniquely equipped to handle.
